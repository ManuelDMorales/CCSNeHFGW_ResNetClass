{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<font size=\"5.5\"><u><i>Convert Strain to Image</i></u></font>"
      ],
      "metadata": {
        "id": "Hs2qXEhZhM9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=\"4\">Script to convert strain samples (time series) to image samples (TF scalograms).</font>\n",
        "<br/>\n",
        "<font size=\"4\">Author: Manuel David Morales</font>"
      ],
      "metadata": {
        "id": "kyCyw8TyhTu9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lekLMB7g7V1",
        "outputId": "419ac3a7-0173-4f8f-b2e7-110a903a5774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive repository\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40X23SO3Dnfb"
      },
      "source": [
        "## 1) Library imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEma2jOCB27o"
      },
      "outputs": [],
      "source": [
        "# Data analysis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Visualization\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "# Scientific computing\n",
        "import scipy.misc\n",
        "from scipy import signal\n",
        "\n",
        "# Files/folders management\n",
        "import os, glob, io\n",
        "\n",
        "# To read csv files\n",
        "import csv\n",
        "\n",
        "# Garbage collector\n",
        "import gc\n",
        "\n",
        "# Image management\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6sFq-_iLArQ"
      },
      "source": [
        "## 2) Input parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpHyw0A7LBj6"
      },
      "outputs": [],
      "source": [
        "# Interferometer for noise data\n",
        "# ------------------------------------------------------------\n",
        "detector = \"L1\"    # Options: \"L1\", \"H1\", \"V1\"\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "# Class of samples to convert\n",
        "# ------------------------------------------------------------\n",
        "sample_class = \"3\"    # Options: \"1\", \"2\", \"3\"\n",
        "# ------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJBIeitSFNwb"
      },
      "source": [
        "## 3) Read files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jz0z5lZjgcvr",
        "outputId": "d4d08244-aece-46cc-feac-ab4dfd9abd18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Strain datasets are located at: /content/drive/MyDrive/Colab Notebooks/GitHub/CCSNeHFGW_ResNetClass/Datasets/\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ------> Specify folder location\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/Colab Notebooks/GitHub/CCSNeHFGW_ResNetClass/Datasets/'\n",
        "print(\"Strain datasets are located at:\", data_dir)\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------\n",
        "# ------> Strain sample and log data files reader\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "def load_straindata(folder_path, class_samples, class_logdata):\n",
        "\n",
        "    \"\"\"\n",
        "    Function to load strain samples for a given class.\n",
        "\n",
        "    INPUT:\n",
        "            folder_path    -> Folder path\n",
        "            class_samples  -> Dictionary, to save strain\n",
        "                              samples for each class (key)\n",
        "            class_logdata  -> Dictionary, to save log\n",
        "                              data for each class (key)\n",
        "\n",
        "    OUTPUT:\n",
        "            class_samples  -> Updated samples dictionary\n",
        "            class_logdata  -> Updated log dictionary\n",
        "            Num_samples    -> No. of loaded samples\n",
        "    \"\"\"\n",
        "\n",
        "    os.chdir(folder_path)\n",
        "    print(folder_path)\n",
        "\n",
        "    # Initialize No. of samples count\n",
        "    Num_samples = 0\n",
        "\n",
        "    # Loop: Waveform class subfolders\n",
        "    # ---------------------------------\n",
        "    for subfolder in glob.glob(\"wfclass_*\"):\n",
        "\n",
        "        print(\"=======> SCANNING\", subfolder, \"SUBFOLDER\")\n",
        "\n",
        "        class_label = subfolder[-1]\n",
        "\n",
        "        os.chdir(folder_path + \"/\" + subfolder)\n",
        "        #print(folder_path + \"/\" + subfolder)\n",
        "\n",
        "        windows_onelabel = []\n",
        "\n",
        "        logdata_onelabel = []\n",
        "\n",
        "        # Loop: Strain window samples\n",
        "        # -----------------------------\n",
        "        for file in glob.glob(\"sample_strain_*\"):\n",
        "\n",
        "            #print(\"***** READING FILE\", file, \" *****\")\n",
        "\n",
        "            # Extract sample number from file\n",
        "            # Remark: Some ordinal numbers could be not present, because\n",
        "            # in strain dataset generation, samples of SNR values outside\n",
        "            # of an acceptation range are removed (SNR>100)\n",
        "            Num_TFsample = int(file[-10:-4])\n",
        "\n",
        "            # -----> Load log data\n",
        "            # ----------------------\n",
        "\n",
        "            # Remark: Read and update log data file is important, because\n",
        "            # reading of strain samples does not following the same order as\n",
        "            # the number of strain samples files. Then, TF samples will\n",
        "            # be not enumerated following the order of the strain samples.\n",
        "\n",
        "            with open(\"log.dat\") as csv_file:\n",
        "\n",
        "                csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "                line_count = 0\n",
        "\n",
        "                for row in csv_reader:\n",
        "\n",
        "                    if line_count == 0:\n",
        "                        #print(f'Data columns: {\", \".join(row)}')\n",
        "                        line_count += 1\n",
        "\n",
        "                    elif line_count == Num_TFsample + 2:\n",
        "                        t_inj = row[0]\n",
        "                        jitter = row[1]\n",
        "                        wf_SNR = row[2]\n",
        "                        Slope = row[3]\n",
        "                        f_ini = row[4]\n",
        "                        f_end = row[5]\n",
        "                        wf_duration = row[6]\n",
        "\n",
        "                        break\n",
        "\n",
        "                    line_count += 1\n",
        "\n",
        "            logdata_onelabel.append([str(Num_TFsample+1), t_inj, jitter, wf_SNR, Slope, f_ini, f_end, wf_duration])\n",
        "\n",
        "            # -----> Load strain data\n",
        "            # -------------------------\n",
        "\n",
        "            with open(file) as csv_file:\n",
        "\n",
        "                sample = pd.read_csv(file)\n",
        "                sample_arr = sample.to_numpy()\n",
        "                windows_onelabel.append(sample_arr)\n",
        "\n",
        "                Num_samples += 1\n",
        "\n",
        "        class_samples[\"class \" + class_label] = windows_onelabel\n",
        "        class_logdata[\"class \" + class_label] = logdata_onelabel\n",
        "\n",
        "    return class_samples, class_logdata, Num_samples"
      ],
      "metadata": {
        "id": "qXiDG_tlqVHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize list for segments GPS initial times\n",
        "GPS_seg = []\n",
        "\n",
        "# Initialize list for strain data by GPS segments\n",
        "strain_segments = []\n",
        "\n",
        "# Initialize list for log data by GPS segments\n",
        "logdata_segments = []\n",
        "\n",
        "# Initialize No. of total injections count\n",
        "Num_samples_total = 0\n",
        "\n",
        "# ------> Scan folders\n",
        "\n",
        "os.chdir(data_dir)\n",
        "\n",
        "# ------> Loop: Segment folders\n",
        "for folder in glob.glob(detector + \"*\"):\n",
        "\n",
        "    print(\"SCANNING\", folder, \"FOLDER\")\n",
        "    print(\"------------------------------------------\")\n",
        "\n",
        "    GPS_seg.append(folder[-10:])\n",
        "\n",
        "    # Initialize dictionary for strain data\n",
        "\n",
        "    class_samples = {}\n",
        "\n",
        "    # Initialize dictionary for log adata\n",
        "\n",
        "    class_logdata = {}\n",
        "\n",
        "    # Call function load_straindata\n",
        "    class_samples, class_logdata, Num_samples = load_straindata(data_dir + folder, class_samples, class_logdata)\n",
        "\n",
        "    strain_segments.append(class_samples)\n",
        "    logdata_segments.append(class_logdata)\n",
        "\n",
        "    Num_samples_total += Num_samples\n",
        "\n",
        "    print(\"\")\n",
        "\n",
        "print(\"***** Total number of loaded samples: \", Num_samples_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6fJ6D83lCyh",
        "outputId": "0108f074-e6fc-4409-eae2-ae1cc4a02683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SCANNING L1_1257050112 FOLDER\n",
            "------------------------------------------\n",
            "/content/drive/MyDrive/Colab Notebooks/GitHub/CCSNeHFGW_ResNetClass/Datasets/L1_1257050112\n",
            "=======> SCANNING wfclass_1 SUBFOLDER\n",
            "=======> SCANNING wfclass_2 SUBFOLDER\n",
            "=======> SCANNING wfclass_3 SUBFOLDER\n",
            "\n",
            "SCANNING L1_1256783872 FOLDER\n",
            "------------------------------------------\n",
            "/content/drive/MyDrive/Colab Notebooks/GitHub/CCSNeHFGW_ResNetClass/Datasets/L1_1256783872\n",
            "=======> SCANNING wfclass_1 SUBFOLDER\n",
            "=======> SCANNING wfclass_3 SUBFOLDER\n",
            "=======> SCANNING wfclass_2 SUBFOLDER\n",
            "\n",
            "SCANNING L1_TF_samples_c1 FOLDER\n",
            "------------------------------------------\n",
            "/content/drive/MyDrive/Colab Notebooks/GitHub/CCSNeHFGW_ResNetClass/Datasets/L1_TF_samples_c1\n",
            "\n",
            "SCANNING L1_TF_samples_c2 FOLDER\n",
            "------------------------------------------\n",
            "/content/drive/MyDrive/Colab Notebooks/GitHub/CCSNeHFGW_ResNetClass/Datasets/L1_TF_samples_c2\n",
            "\n",
            "***** Total number of loaded samples:  3053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------> Some checks\n",
        "\n",
        "print(\"Key of dictionaries in strain_segments lists:\")\n",
        "print(\"-----------------------------------------------\")\n",
        "print(strain_segments[0].keys())\n",
        "print(strain_segments[1].keys())\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print(\"Key of dictionaries in logdata_segments lists:\")\n",
        "print(\"-----------------------------------------------\")\n",
        "print(logdata_segments[0].keys())\n",
        "print(logdata_segments[1].keys())\n",
        "# Remark: In strain_segments[n] and logdat_segments[n],\n",
        "#         n value is the folder's number of a strain GPS segment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwreD5vynHzj",
        "outputId": "6edc4627-9f88-42dc-a6b7-1e95237354cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key of dictionaries in strain_segments lists:\n",
            "-----------------------------------------------\n",
            "dict_keys(['class 1', 'class 2', 'class 3'])\n",
            "dict_keys(['class 1', 'class 3', 'class 2'])\n",
            "\n",
            "Key of dictionaries in logdata_segments lists:\n",
            "-----------------------------------------------\n",
            "dict_keys(['class 1', 'class 2', 'class 3'])\n",
            "dict_keys(['class 1', 'class 3', 'class 2'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEFwMTcMcFOj"
      },
      "source": [
        "## 4) Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hereinafter, the analysis is performed only for the selected class"
      ],
      "metadata": {
        "id": "46bpCprsFkP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------> Initial checks\n",
        "\n",
        "print(\"Count of samples in segments of class\", sample_class, \":\")\n",
        "print(\"-----------------------------------------\")\n",
        "print(\"\")\n",
        "\n",
        "for i in [0,1]:\n",
        "    print(\"---> GPS Segment\", GPS_seg[i])\n",
        "    #print(\"****************\")\n",
        "    print(\"Strain files: \", len(strain_segments[i][\"class \" + sample_class]))\n",
        "    print(\"Log data files: \", len(logdata_segments[i][\"class \" + sample_class]))\n",
        "    print(\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxVanAFsRtB7",
        "outputId": "68732812-d93d-4f61-f0ec-1aacde93c05e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of samples in segments of class 3 :\n",
            "-----------------------------------------\n",
            "\n",
            "---> GPS Segment 1257050112\n",
            "Strain files:  506\n",
            "Log data files:  506\n",
            "\n",
            "---> GPS Segment 1256783872\n",
            "Strain files:  508\n",
            "Log data files:  508\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------> Convert log data lists to numpy arrays of floats\n",
        "\n",
        "for seg in [0,1]:\n",
        "    for i in range(len(logdata_segments[seg][\"class \" + sample_class])):\n",
        "        # List of strings to list of floats\n",
        "        logdata_segments[seg][\"class \" + sample_class][i] = [float(x) for x in logdata_segments[seg][\"class \" + sample_class][i]]\n",
        "        # List of floats to array of floats\n",
        "        logdata_segments[seg][\"class \" + sample_class][i] = np.array(logdata_segments[seg][\"class \" + sample_class][i])\n",
        "\n",
        "    logdata_segments[seg][\"class \" + sample_class] = np.array(logdata_segments[seg][\"class \" + sample_class])"
      ],
      "metadata": {
        "id": "0aXBrpZR4HHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------> Sort log data arrays by first row (ordinal number)\n",
        "\n",
        "for seg in [0,1]:\n",
        "\n",
        "    # Copy main array as a temporary array\n",
        "    temp_arr = logdata_segments[seg][\"class \" + sample_class]\n",
        "\n",
        "    # Sort temporary array\n",
        "    temp_arr = temp_arr[temp_arr[:, 0].argsort()]\n",
        "\n",
        "    # Reasigne main array\n",
        "    logdata_segments[seg][\"class \" + sample_class] = temp_arr\n",
        "\n",
        "    # Delete temporary array\n",
        "    del(temp_arr)\n",
        "    gc.collect()"
      ],
      "metadata": {
        "id": "mVUlqK_xDgio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------> Concatenate arrays of logdata segments for the selected class\n",
        "\n",
        "logdata = np.concatenate((logdata_segments[0][\"class \" + sample_class], logdata_segments[1][\"class \" + sample_class]), axis=0)\n",
        "\n",
        "#Check\n",
        "print(\"Shape of logdata array with ordinal numbers: \", logdata.shape)\n",
        "\n",
        "# ------> Remove ordinal numbers\n",
        "\n",
        "logdata = np.delete(logdata, 0, 1)\n",
        "\n",
        "# Check\n",
        "print(\"Shape of logdata array ordinal numbers: \", logdata.shape)\n",
        "\n",
        "# Remark for checks:\n",
        "# 1st dimension -> Number of window strain samples\n",
        "# 2nd dimension -> Number of log variables for each sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWmB4gbhFf2x",
        "outputId": "40e7f561-de23-4eb6-aa00-3bb6056f9a02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of logdata array with ordinal numbers:  (1014, 8)\n",
            "Shape of logdata array ordinal numbers:  (1014, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------> Merge lists of strain samples and convert to numpy array\n",
        "\n",
        "samples =  strain_segments[0][\"class \" + sample_class] + strain_segments[1][\"class \" + sample_class]\n",
        "samples = np.array(samples)\n",
        "\n",
        "# Check\n",
        "print(\"Shape of samples array:\", samples.shape)\n",
        "\n",
        "# Remark:\n",
        "# 1st dimension -> Number of window strain samples\n",
        "# 2nd dimension -> Window strain sample length\n",
        "# 3rd dimension -> Features; time [s] and strain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUJ7l5IzGs0W",
        "outputId": "4aa425b2-03e5-40a7-d44f-6e25b5cf4afd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of samples array: (1014, 3971, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------> Compute sampling frequency\n",
        "\n",
        "fs = 1 / (np.transpose(samples[0])[0][1] - np.transpose(samples[0])[0][0])\n",
        "print(\"Sampling frequency of window strain samples:\", fs)"
      ],
      "metadata": {
        "id": "EtaVh_TH5dYv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da786379-8a64-4cb5-eec5-68b655298033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling frequency of window strain samples: 4096.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWn8VNVzdZDK"
      },
      "source": [
        "## 5) Samples conversion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1pTCR4LeiGB"
      },
      "source": [
        "Next cell contains functions to compute wavelet transform"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# ---------------------------------------------------------------\n",
        "# ------> Wavelet time-frequency representation\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "def WaveletTF_transform(h, fs, fstart, fstop, delta_f, width, doplots):\n",
        "\n",
        "    \"\"\"\n",
        "    This function computes the time-frequency representation\n",
        "    based on a Wavelet transform of a signal (time series)\n",
        "\n",
        "    INPUT:\n",
        "            h        -> Signal\n",
        "            fs       -> Sampling frequency\n",
        "            fstart   -> Filter's initial frequency\n",
        "            fstop    -> Filter's final frequency\n",
        "            delta_f  -> Frequency bin width\n",
        "            width    -> Width of the wavelet (in cycles)\n",
        "            doplots  -> Do plots for checks (0: no, 1: yes)\n",
        "\n",
        "    OUTPUT:\n",
        "            timeVec  -> Vector of times\n",
        "            freqVec  -> Vector of frequencies\n",
        "            WL       -> Wavelet coefficients\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # ------> Time vector and time sampling\n",
        "\n",
        "    Nsamples = len(h)\n",
        "    timeVec = np.arange(0, Nsamples)/fs\n",
        "    ts      = 1/fs\n",
        "\n",
        "    # ------> Frequency vector\n",
        "\n",
        "    Nfreq = round((fstop - fstart) / delta_f) + 1\n",
        "    freqVec = np.linspace(fstart, fstop, Nfreq).reshape((-1, 1))\n",
        "\n",
        "    # ------> Initialize Wavelet Transform Matrix\n",
        "\n",
        "    WL = np.zeros((Nfreq, Nsamples))\n",
        "\n",
        "    #print(\"Wavelet Transform Matrix shape:\", WL.shape)\n",
        "\n",
        "    # ------> Compute the time-frequency representation\n",
        "\n",
        "    signal = h\n",
        "    #signal = detrend(h, axis=-1, type='linear')\n",
        "\n",
        "    for ifre in range(Nfreq):\n",
        "\n",
        "        # Compute the Morlet wavelet\n",
        "        Morlet = Morlet_wavelet(freqVec[ifre], ts, width, doplots);\n",
        "\n",
        "        # Apply the Morlet wavelet transform\n",
        "        WLcomplex = np.convolve(signal, Morlet, mode='full')\n",
        "\n",
        "        # Get indexes\n",
        "        li = int(np.ceil(len(Morlet) / 2))\n",
        "        ls = li + Nsamples\n",
        "        #ls = len(WLcomplex) - int(np.flor(len(Morlet) / 2))\n",
        "\n",
        "        # Complex coefficients\n",
        "        WLcomplex = WLcomplex[li:ls]\n",
        "\n",
        "        if doplots:\n",
        "\n",
        "            print(\"Frecuency =\", freqVec[ifre])\n",
        "            print(\"++++++++++++++++++++++++++++++++++++++++\")\n",
        "            print(\"\")\n",
        "\n",
        "            plt.figure()\n",
        "            plt.subplot(3, 1, 1)\n",
        "            plt.plot(np.real(WLcomplex), 'r')\n",
        "            plt.plot(np.imag(WLcomplex), 'b')\n",
        "            plt.legend(['real', 'imag'])\n",
        "            plt.box(True)\n",
        "            plt.title('Frequency: ' + str(freqVec[ifre]) + ' Hz')\n",
        "\n",
        "            plt.subplot(3, 1, 2)\n",
        "            plt.plot(np.abs(WLcomplex))\n",
        "            plt.legend(['magnitude'])\n",
        "            plt.box(True)\n",
        "\n",
        "            plt.subplot(3, 1, 3)\n",
        "            plt.plot(np.angle(WLcomplex))\n",
        "            plt.legend(['phase'])\n",
        "            plt.box(True)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.pause(0.1)  # Pause for a short time to show the plot\n",
        "            #plt.savefig('wavelet_decomposition.png')\n",
        "\n",
        "        # Compute the magnitude\n",
        "        WLmag = 2*(np.abs(WLcomplex)**2)/fs\n",
        "\n",
        "        # Save wavelet decomposition magnitude\n",
        "        WL[ifre, :] = WLmag\n",
        "\n",
        "        WL = np.squeeze(WL)\n",
        "\n",
        "        if doplots:\n",
        "\n",
        "            plt.figure()\n",
        "            X, Y = np.meshgrid(timeVec, freqVec)\n",
        "\n",
        "            plt.pcolormesh(X, Y, WL[:, :], shading='gouraud')\n",
        "\n",
        "            plt.axis([np.min(timeVec), np.max(timeVec), np.min(freqVec), np.max(freqVec)])\n",
        "            plt.xlabel('Time (s)')\n",
        "            plt.ylabel('Frequency (Hz)')\n",
        "            plt.title('Time-Frequency representation')\n",
        "            plt.box(True)\n",
        "            plt.colorbar()\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "    return timeVec, freqVec, WL\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# ------> Morlet Wavelet time-frequency representation\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "def Morlet_wavelet(fi, ts, morlet_w, doplots):\n",
        "\n",
        "    \"\"\"\n",
        "    Function to compute the Complex Morlet Wavelet for frequency \"fi\"\n",
        "    and time \"t\". This will be normalized so the total energy = 1.\n",
        "\n",
        "    INPUT:\n",
        "            fi        -> Frequency\n",
        "            ts        -> Sampling time\n",
        "            morlet_w  -> Wavelet's width (width>= 5 is suggested)\n",
        "            doplots   -> Do plots for checks (0: no, 1: yes)\n",
        "\n",
        "    OUTPUT:\n",
        "            Morlet    -> Morlet wavelet\n",
        "    \"\"\"\n",
        "\n",
        "    # Frequency standard deviation\n",
        "    sf = fi / morlet_w\n",
        "\n",
        "    # Time standard deviation\n",
        "    st = 1/(2*np.pi*sf)\n",
        "\n",
        "    # Wavelet's amplitude\n",
        "    A  = 1/np.sqrt(st*np.sqrt(np.pi))\n",
        "\n",
        "    # Time array\n",
        "    t = np.arange(-3.5 * st, 3.5 * st + ts, ts)\n",
        "\n",
        "    # Compute Morlet wavelet\n",
        "    Morlet =  A*np.exp(-t**2/(2*st**2))*np.exp(1j*2*np.pi*fi*t)\n",
        "\n",
        "    if doplots:\n",
        "\n",
        "        plt.figure()\n",
        "\n",
        "        plt.subplot(3, 1, 1)\n",
        "        plt.plot(t, np.real(Morlet), 'r', linewidth=2)\n",
        "        plt.plot(t, np.imag(Morlet), 'b', linewidth=2)\n",
        "        plt.ylabel('Morlet')\n",
        "        plt.legend(['Real', 'Imag'])\n",
        "        plt.box(True)\n",
        "        plt.title('Frequency = ' + str(fi) + 'Hz')\n",
        "\n",
        "        plt.subplot(3, 1, 2)\n",
        "        plt.plot(t, np.abs(Morlet), '.-r')\n",
        "        # plt.axis([-4, 4, 0, 6])\n",
        "        plt.xlabel('Time (s)')\n",
        "        plt.ylabel('Magnitude')\n",
        "\n",
        "        plt.subplot(3, 1, 3)\n",
        "        plt.plot(t, np.angle(Morlet), '.-b')\n",
        "        # plt.axis([-4, 4, -4, 4])\n",
        "        plt.xlabel('Time (s)')\n",
        "        plt.ylabel('Angle')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    return Morlet"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gDE3iYqJuKf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------> Create folder to save samples\n",
        "\n",
        "dir_TFsamples = \"/content/drive/MyDrive/Colab Notebooks/GitHub/CCSNeHFGW_ResNetClass/Datasets/\"\n",
        "\n",
        "if not os.path.isdir(dir_TFsamples + detector + \"_TF_samples_c\" + sample_class):\n",
        "\n",
        "    os.makedirs(dir_TFsamples + detector + \"_TF_samples_c\" + sample_class)\n",
        "\n",
        "# ------> Set location of the folder\n",
        "\n",
        "dir_TFsamples = dir_TFsamples + detector + \"_TF_samples_c\" + sample_class + \"/\"\n",
        "os.chdir(dir_TFsamples)\n",
        "print(\"Directory to save images:\", dir_TFsamples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7t2xBP2fSRE",
        "outputId": "c773bc83-d51b-459c-be24-610b137ce632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory to save images: /content/drive/MyDrive/Colab Notebooks/GitHub/CCSNeHFGW_ResNetClass/Datasets/L1_TF_samples_c3/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------> Save new log data file\n",
        "\n",
        "np.save('log_TFsamples', logdata)"
      ],
      "metadata": {
        "id": "JtdoMqQ9TbHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------> Convert samples to images and save them\n",
        "\n",
        "#for i in range(len(samples)):\n",
        "for i in range(10): # For debugging\n",
        "\n",
        "    # Transpose sample array\n",
        "    sample = np.transpose(samples[i])\n",
        "\n",
        "    # Print the current sample's number being converted\n",
        "    print(\"Converting window sample \", i)\n",
        "\n",
        "    # Generate TF representation\n",
        "    time, freq, Sxx = WaveletTF_transform(sample[1], fs, 10, 2000, 10, 7, 0)\n",
        "\n",
        "    # Plot and save TF representation\n",
        "    plt.figure(i, figsize=(1,1))\n",
        "    plt.pcolormesh(time+sample[0][0], freq, Sxx, shading='gouraud')\n",
        "    plt.xlabel('Time [s]'); plt.ylabel('Freq [Hz]')\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    TF_sample = io.BytesIO()\n",
        "    plt.savefig(TF_sample, bbox_inches='tight', pad_inches=0, format='jpg')\n",
        "\n",
        "    # Convert matplotlib figure to PIL image\n",
        "    img = Image.open(TF_sample)\n",
        "\n",
        "    # Resize PIL image\n",
        "    img_resized = img.resize((64, 64))\n",
        "\n",
        "    TF_sample.close()\n",
        "    #!rm TF_sample\n",
        "\n",
        "    # Convert PIL resized image to RGB\n",
        "    if img_resized.mode != 'RGB':\n",
        "        img_resized = img_resized.convert('RGB')\n",
        "\n",
        "    sample_number = str(i).zfill(6)\n",
        "\n",
        "    # Save PIL resized RGB image\n",
        "    img_resized.save('TF_sample_' + sample_number + '.jpg')\n",
        "\n",
        "    # Save PIL resized RGB image as numpy array\n",
        "    img_array = np.array(img_resized)\n",
        "    np.save('TF_sample_' + sample_number, img_array)\n",
        "\n",
        "    #plt.show()\n",
        "\n",
        "    plt.figure(i).clear()\n",
        "    plt.close()\n",
        "    gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdUkW1tCwz0B",
        "outputId": "71941322-659e-4657-9761-83b6a8b1df1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting window sample  0\n",
            "Converting window sample  1\n",
            "Converting window sample  2\n",
            "Converting window sample  3\n",
            "Converting window sample  4\n",
            "Converting window sample  5\n",
            "Converting window sample  6\n",
            "Converting window sample  7\n",
            "Converting window sample  8\n",
            "Converting window sample  9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bwH0ni4MLdja"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}